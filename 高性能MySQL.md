# 高性能MySQL

[TOC]



## MySQL架构与历史

### MySQL逻辑架构

- 第一层（连接器）负责连接/线程处理；
- 第二层（查询缓存、解析器、优化器）实现大多数MySQL的核心服务功能，所有跨存储引擎的功能都在这一层实现；
- 第三层（存储引擎）包含了存储引擎，存储引擎负责MySQL中数据的存储和提取。存储引擎不会去解析SQL（除了InnoDB解析外键），不同存储引擎之间也不会相互通信，只是简单地响应上层服务器的请求；

#### 连接管理与安全性

每个客户端连接都会在服务器进程中拥有一个线程，这个连接的查询只会在这个单独的线程中执行，该线程只能轮流在某个CPU核心或CPU中运行。服务器会负责缓存线程，因此不需要为每个新建的连接创建或销毁线程（新的客户端可以使用之前缓存的连接）（MySQL5.5及以上提供了一个API，支持线程池插件，可以使用池中少量的线程来服务大量的连接）；

#### 优化与执行

- MySQL会解析查询，并创建内部数据结构（解析树），然后对其进行各种优化，包括重写查询、决定表的读取顺序，以及选择合适的索引等；
- 优化器并不关心表使用的是什么存储引擎，但是存储引擎对于优化查询是有影响的。优化器会请求存储引擎提供容量或某个具体操作的开销信息，以及表数据的统计信息等；
- 对于select语句，在解析查询之前，服务器会先检查查询缓存，如果能命中缓存，则不必再执行查询解析、优化和执行的整个过程；

### 并发控制

#### 读写锁

在处理并发读或写时，可以通过实现一个由两种类型的锁系统来解决问题，这两种类型的锁通常被成为共享锁（shared lock）和排他锁（exclusive lock），也叫读写和写锁；

#### 锁粒度

每种MySQL存储引擎可以实现自己的锁策略（在锁的开销和数据的安全性之间寻求平衡）和锁粒度。

**表锁（table lock）**

- 表锁是MySQL中最基本的锁策略，并且是开销最小的策略。用户在对表进行写操作前需要先获得写锁，这会阻塞其他用户对该表的所有读写操作，读锁之间是不相互阻塞的；
- 在特定的场景中，表锁也可能有良好的性能。例如READ LOCAL表锁支持某些类型的并发写操作，另外写锁也比读锁有更高的优先级，读锁请求可能会被插入到写锁的前面个；

**行级锁（row lock）**

行级锁可以最大程度地支持并发处理，同时也带来了最大的锁开销。行级锁只在存储引擎层实现，InnoDB实现了行级锁；

### 事务

ACID表示原子性（atomicity）、一致性（consistency）、隔离性（isolation）、持久性（durability）；

事务就是一组原子性的SQL，事务内的语句要么全部执行成功，要么全部执行失败；

#### 隔离级别

| 级别                                | 说明                                                         | 使用场景                                                     |
| ----------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| READ UNCOMMITTED（未提交读）        | 事务可以读取未提交的数据（脏读）                             | 很少使用                                                     |
| READ COMMITTED（提交读/不可重复读） | 事务只能读取已被提交的修改                                   | 大多数数据库系统的默认级别（但是MySQL不是）                  |
| REPETABLE READ（可重复读）          | 保证同一事务中多次读取同样的记录的结果是一致的               | MySQL的默认事务隔离级别                                      |
| SERIALIABLE（可串行化）             | 通过强制事务串行执行而避免幻读，SERIALIABLE会在读取的每一行数据上都加锁，所以可能导致大量的超时和锁争用问题 | 很少使用，只有在非常需要确保是根据一致性而且可以接受没有并发的情况下，才会考虑采用该级别 |

| 隔离级别         | 脏读 | 不可重复读 | 幻读 | 加锁读 |
| ---------------- | ---- | ---------- | ---- | ------ |
| READ UNCOMMITTED | 是   | 是         | 是   | 否     |
| READ COMMITTED   | 否   | 是         | 是   | 否     |
| REPETABLE READ   | 否   | 否         | 是   | 否     |
| SERIALIABLE      | 否   | 否         | 否   | 是     |

- **脏读**：事务可以读取别的事务未提交的数据；
- **不可重复读**：事务A读取了一条数据，在执行逻辑时，事务B将其改变了，然后A再次读取的时候，发现数据不匹配了；
- **幻读**：事务A首先根据条件得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N + M条数据；

#### 死锁

- 死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。
- 为解决死锁问题，数据库系统实现了各种死锁检测和死锁超时机制，越复杂的系统，如InnoDB存储引擎，越能检测到死锁的循环依赖，并立即返回一个错误。还有一种解决方式，就是当查询的时间达到锁等待超时的设定后放弃锁请求，这种方式通常来说不太好；
- InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚；

#### 事务日志

- 事务日志可以帮助提高事务的效率。使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘；
- 事务日志持久以后，内存中被修改的数据在后台可以慢慢地刷回磁盘，目前大多数存储引擎都是这样实现的，我们通常称之为预写式日志（Write-Ahead Logging），修改数据需要写两次磁盘；

#### MySQL中的事务

**自动提交**

MySQL默认采用自动提交（AUTOCOMMIT）模式，即如果不显式地开始一个事务，则每个查询都被当作一个事务执行提交操作；

**在事务中混合使用存储引擎**

由于事务是由下层存储引擎实现的，所以在同一个事务中，使用多种存储引擎是不可靠的；

**隐式和显示锁定**

- InnoDB采用的是两阶段锁定协议，在事务执行过程种，随时都可以执行锁定，锁只有在执行Commit或Rollback时才会释放，并且所有的锁是在同一时刻被释放。前面描述的锁定都是隐式锁定，InnoDB会根据隔离级别在需要的时候自动加锁；
- 另外InnoDB也支持通过特定的语句进行显式锁定，这些语句不属于SQL规范（因此应当尽量避免使用）；

- `select ... lock in share mode`
- `select ... for update`

### 多版本并发控制

- MySQL的大多数事务型存储引擎实现的都不是简单的行级锁，基于提升并发性能的考虑，他们一般都同时实现了**多版本并发控制**（MVCC）；
- 可以认为MVCC是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此开销更低；
- MVCC的实现，是通过保存数据在某个时间点的快照来实现的，也就是说，不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的；

**InnoDB的MVCC**

InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现的，一个保存了行的创建时间，一个保存行的过期时间（或删除时间），存储的不是时间的时间值，而是系统版本号。每开始一个新的事务，系统版本号都会递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。REPEATABLE READ隔离级别下，MVCC的具体操作：

- SELECT：InnoDB会根据以下两个条件查询每行记录：a.InnoDB只查找版本早于（小于等于）当前事务版本的数据行，这样可以确保读取的行要么是在事务开始前已存在的，要么是事务自身插入或修改的；a.行的删除版本要么未定义，要么大于当前事务版本号，这样可以确保事务读取到的行，在事务开启前未被删除；
- INSERT：InnoDB为新插入的每一行保存当前系统版本号作为行版本号；
- DELETE：InnoDB为删除的每一行保存当前系统版本号作为行删除标识；
- UPDATE：InnoDB为插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本到原来的行作为行删除标识；

MVCC只在可重复读和已提交读两个隔离级别下工作；

### MySQL的存储引擎

#### InnoDB存储引擎

InnoDB是MySQL的默认事务型引擎，也是最重要、使用最广泛的存储引擎。

**InnoDB概览**

- InnoDB的数据存储在表空间（tablespace）中，表空间是由InnoDB管理的一个黑盒子，由一系列的数据文件组成；
- InnoDB采用MVCC来支持高并发，并且实现了四个标准的隔离级别，默认级别是可重复读，并通过间隙锁策略防止幻读的出现（间隙锁使得InnoDB不仅仅锁定查询涉及的行，还会对索引中的间隙进行锁定，以防止幻影行的插入）；
- InnoDB表是基于聚簇索引建立的。InnoDB的索引结构和MySQL的其他存储引擎有很大的不同，聚簇索引对主键查询有很高的性能。不过它的二级索引（非主键索引）中必须包含主键列，所以如果主键列很大的话，其他的所有索引都会很大，因此如果表上的索引较多的话，主键应当尽可能的小；
- InnoDB内部做了很多优化，包括从磁盘读取数据时采用的可预测性预读，能够自动在内存中创建hash索引以加速读操作的自适应哈希索引，以及能够加速插入操作的插入缓冲区等；
- 作为事务型的存储引擎，InnoDB通过一些机制和工具支持真正的热备份；

#### MyISAM存储引擎

- MyISAM提供了大量的特性，包括全文索引、压缩、空间函数等，但是MyISAM不支持事务和行级锁，而且有崩溃后无法安全恢复的缺陷；
- MyISAM并非一无是处，对于只读的数据，或者表比较小，可以忍受repair操作，则依然可以继续使用MyISAM；

**MyISAM压缩表**

如果表在创建并导入数据以后不会再进行修改操作，那么这样的表或许适合采用MyISAM压缩表，可以使用myisampack对MyISAM表进行压缩，压缩表不能修改，可以极大地减少磁盘空间占用，因此也可以减少磁盘IO，从而提升查询性能；压缩表也支持索引，但是索引也是只读的；

**MyISAM性能**

最典型的性能问题是表锁的问题

#### MySQL内建的其他存储引擎

**CSV引擎**

可以把普通的CSV文件作为MySQL的表来处理，不支持索引。CSV引擎可以作为一种数据交换的机制；

**MEMORY引擎**

- 如果需要快速地访问数据，并且这些数据不会被修改，重启后丢失也没有关系，那么使用Memory表是非常有用地；
- 至少比MyISAM表快一个数量级，因为数据保存在内存中，不需要进行磁盘IO；
- Memory表在很多场景可以发挥好的作用：a.用于查找或者映射的表，例如将邮编和州名映射的表；b.用于缓存周期性聚合数据的结果；c.用于保存数据分析中产生的中间数据；
- Memory表支持Hash索引，因此查找操作非常快。Memory表是表级锁，因此并发写入的性能较低。它不支持BLOB或TEXT类型的列，并且每行的长度是固定的；

## MySQL基准测试

基准测试（benchmark）是针对系统设计的一种压力测试

### 基准测试方法

#### 测试指标

- **吞吐量**：单位时间内的事务处理数；
- **响应时间或者延迟**：测试任务所需的整体时间，通常可以使用百分比响应时间来替代最大响应时间；
- **并发性**：任意时间有多少同时发生的并发请求；
- **可扩展性**：给系统增加一倍的资源，可以获得两倍的吞吐量；

#### 基础测试应该运行多长时间

等系统看起来稳定的时间至少等于系统预热的时间；

## Schema与数据类型优化

### 选择优化的数据类型

MySQL支持的数据类型非常多，选择正确的数据类型对于获得高性能至关重要。

- **更小的通常更好**：尽量使用可以正确存储数据的最小数据类型。最小的数据类型通常更快，因为它们占用更少的磁盘、内存和CPU缓存，并且处理时需要的CPU周期也更少；
- **简单就好**：简单数据类型的操作需要更少的CPU周期。例如，整型比字符操作代价更低（因为字符集和校对规则使字符比较比整型比较更复杂），应该使用MySQL内建的类型而不是字符串来存储日期和时间；
- **尽量避免NULL**：通常情况下最好指定列为NOT NULL，除非真的需要存储NULL值，因为NULL的列使得索引、索引统计和值比较都更复杂，可为NULL的列会使用更多的存储空间。（InnoDB使用单独的位(bit)存储NULL值，所以对于稀疏数据有很好的空间效率，但这一点不适用于MyISAM）；

#### 整数类型

- 存储整数可使用TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别使用8、16、24、32、64位存储空间；
- 整数类型有可选UNSIGNED属性，表示不允许负值，这大致可以使正数的上限提高一倍；

#### 实数类型

- FLOAT和DOUBLE类型支持使用标准的浮点运算进行近似计算，如果需要知道浮点运算是怎么计算的，则需要研究所使用的平台的浮点数的具体实现；
- Decimal类型用于存储精确的小数，CPU不支持DECIMAL的直接计算，而是由MySQL服务器自身实现DECIMAL的高精度计算，相对而言，CPU直接支持原生浮点计算，所以浮点运算明显更快；
- 浮点类型在存储同样范围的值时，通常比DECIMAL使用更少的空间。因为需要额外的空间和计算开销，所以应该尽可能只在对小数进行精确计算时才使用DECIMAL，但在数据量比较大的时候，可以考虑使用BIGINT代替DECIMAL（将需要存储的货币单位根据小数的位数乘以相应的倍数即可）；

#### 字符串类型

**VARCHAR**

- 用于存储可变长字符串，比定长类型更节省空间；
- 使用1或2个额外字节记录字符串的长度（如果列的最大长度小于等于255，则使用2个，否则使用1个）；
- 适合使用VARCHAR的场景：1.字符串列的最大长度比平均长度大很多；2.列的更新很少，碎片不是问题；3.使用了UTF-8字符集，每个字符都使用不同的字节数存储；

**CHAR**

MySQL根据定义的字符串长度分配足够的空间，当存储char值时，MySQL会删除所有的末尾空格；

**BLOB和TEXT类型**

- BLOB和TEXT都是为存储很大的数据而设计的字符串数据类型，分别采用二进制和字符方式存储；
- MySQL不能将BLOB和TEXT列全部长度的字符串进行索引，也不能使用这些索引消除排序；

#### 日期和时间类型

- DATETIME能保存1001年到9999年，精度为秒的值；
- TIMESTAMP只使用4个字节的存储空间，除了特殊行为之外，通常应该尽量使用TIMESTAMP，因为它比DATETIME空间效率更高；

#### 位数据类型

可以使用BIT列在一列中存储一个或多个true / false值，MySQL把BIT当作字符串类型，而不是数字类型；

#### 选择标识符（identifier）（主键）

- 在可以满足值得范围得需求，并且预留未来增长空间的前提下，选择最小的数据类型；
- 整数通常是最好的选择，因为它们很快并且可以使用AUTO_INCREMENT；
- 如果可能，应该避免使用字符串类型作为标识列，因为它们很消耗空间，并且通常比数字类型慢。对于完全“随机”的字符串也需要多加注意，例如MD5()、SHA1()或UUID()产生的字符串，这些函数生成的新值会任意分布在很大的空间内，这会导致INSERT以及一些SELECT语句变得很慢（1.因为插入值会随机地写到索引的不同位置，所以使INSERT语句更慢；2.SELECT语句会变得很慢，因为逻辑上相邻的行会分布在磁盘和内存的不同地方；3.随机值导致缓存对所有类型的查询语句效果都很差，因为会使得缓存赖以工作的访问局部性原理失效）；

### MySQL schema设计中的陷阱

**太多的列**

MySQL的存储引擎API工作时需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列，从行缓冲中将编码过的列转换成数据结构的操作代价是非常高的；

**太多的关联**

MySQL限制了每个关联操作最多只能有61张表，如果希望查询执行得快速且并发性好，单个查询最好在12个表以内做关联；

### 范式与反范式

第一范式：字段是最小的单元不可再分；

第二范式：在一的基础之上，表中的字段必须完全依赖于全部主键而非部分主键；

第三范式：在二的基础上，非主键外的所有字段必须互不依赖（消除冗余）；

第四但是：在三的基础上，消除表中的多值依赖；

#### 范式的优点和缺点

**优点**

- 范式化的更新操作通常更快；
- 当数据较好地范式化时，就只有很少地或没有重复数据，所以只需要修改更少地数据；
- 范式化地表通常更小，可以更好地放在内存里，所有执行操作会更快；
- 很少有多余的数据意味着检索列表数据时更少需要DISTINCT或GROUP BY语句；

**缺点**

查询时需要关联，这不但代价昂贵，也可能使一些索引策略无效；

#### 反范式的优点和缺点

反范式化的schema因为所有数据都在一张表中，可以很好地避免关联；

## 创建高性能的索引

### 索引基础

#### 索引的类型

**B-Tree索引**

- B-Tree索引使用B-Tree数据结构来存储数据（很多存储引擎，如InnoDB实际上使用的是B+Tree），大多数MySQL引擎都支持这种索引；
- 使用B-Tree索引，存储引擎不再需要进行全表扫描来获取需要的数据，而是从根节点开始进行搜索，根据根节点的槽中的指针向下层查找，通过比较节点页的值和要查找的值的可以找到合适的指针进入下层子节点，直到在叶子节点（叶子节点的指针指向被索引的数据）中找到要查找的数据；

**B-Tree树与B+Tree的区别**：B-Tree每个节点会存储key和value，B+Tree非叶子节点只存储key。叶子节点存储value，因此B+Tree可以加大每个节点存储的key值数量，降低B+Tree的高度；

B-Tree索引适用于全键值、键值范围或键前缀查找（根据最左前缀的查找）：

- 全值匹配；
- 匹配最左前缀：对多个值建立索引时，从最左边列开始匹配；
- 匹配列前缀：可以只匹配某一列的值的开头部分，如`like 'xx%'`；
- 匹配范围值：匹配列在一个范围（范围过大时会放弃索引而使用全表扫描）；
- 精准匹配某一列并范围匹配另外一列（对多个值建立索引时）；

B-Tree索引的限制：

- 如果不是按照索引的最左列开始查找，则无法使用索引；
- 不能跳过索引中的列；（针对复合索引的情况，依然是按照匹配最左前缀的规则）
- 如果查询中有某个列的范围查询，则其右边的列都无法使用索引优化查找；（针对复合索引）

**哈希索引**

基于哈希表实现，只有精确匹配索引的所有列的查询才有效，对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码，哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存每个数据行的指针。

在MySQL中，只有Memory引擎显示支持哈希索引，这也是Memory引擎表的默认引擎；

**空间数据索引（R-Tree）**

**全文索引**

### 索引的优点

- 大大减少了服务器需要扫描的数据量；
- 可以帮助服务器避免排序和临时表；
- 索引可以将随机I/O变为顺序I/O；

### 高性能的索引策略

#### 独立的列

如果查询中的列不是独立的，则MySQL不会使用索引，即索引列不能是表达式的一部分，也不能是函数的参数。应该始终将索引列单独放在比较符号的一侧；

#### 前缀索引和索引选择性

- 前缀索引：对开始的部分字符上建立索引，这样可以大大节约索引空间，从而提高索引效率，对于BLOB、TEXT或很长的VARCHAR类型的列，必须使用前缀索引；
- 索引选择性：不重复的索引值与数据表的记录总数的比值，值越高则查询性能越高。唯一索引的选择性是1，性能最好；

#### 多列索引（复合索引）

在多个列上建立独立的索引大部分情况下并不能提高MySQL的查询性能：

- 当出现服务器对多个索引做相交操作时（通常有多个AND条件），通常意味着需要一个包含所有相关列的多列索引，而不是多个独立的单列索引；
- 当服务器需要对多个索引做联合操作时（通常有多个OR条件），通常需要耗费大量CPU和内存资源在算法的缓存、排序和合并操作上；
- 更重要的是，优化器不会把这些计算到查询成本中，这会使得查询的成本被低估，导致该执行计划还不如直接走全表扫描；

#### 选择合适的索引列排序

正确的顺序依赖于使用该索引的查询，并且同时需要考虑如何更好地满足排序和分组的需要；

#### 聚簇索引

- 聚簇索引并不是一种单独的索引类型，而是一种数据存储方式，InnoDB的聚簇索引实际上在同一个结构中保存了B-Tree索引和数据行；
- 当表有聚簇索引时，其数据行实际存放在索引的叶子页，术语聚簇表示数据行和相邻的键值紧凑地存储在一起。因为无法同时把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引；
- InnoDB通过主键聚集数据，如果没有定义主键，InnoDB会选择一个唯一的非空索引代替，如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引；

**优点**：

- 可以把相关的数据保存在一起。根据ID聚集数据，只需要从磁盘读取少许的数据页就能获取某个用户的全部邮件；
- 数据访问更快。聚簇索引将索引和数据保存在同一个B-Tree中，因此从聚簇索引中获取数据通常比在非聚簇索引中查找要快；
- 使用覆盖索引扫描的查询可以直接使用页节点中的主键值；

**缺点**

- 聚簇数据最大限度地提高了I/O密集型应用的性能，但如果数据全部都放在内存中，则访问顺序就没那么重要了，聚簇索引也就没什么优势了；
- 插入速度严重依赖于插入顺序。按主键顺序插入是加载数据到InnoDB表中速度最快的方式；
- 更新聚簇索引列的代价很高，因为会强制InnoDB将每个被更新的行移动到新的位置；
- 基于聚簇索引的表在插入新行，或者主键被更新导致需要移动行的时候，可能面临“页分裂”的问题。当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，这就是一次页分裂操作；
- 聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候；
- 二级索引（非聚簇索引）可能比想象的要更大，因为在二级索引的叶子节点包含了引用行的主键列；
- 二级索引访问需要两次索引查找，而不是一次（因为二级索引中保存的是行指针）；

最好避免随机聚簇索引，特别是对于I/O密集型的应用，因为它会使得聚簇索引的插入变得随机；

#### 覆盖索引

- 如果一个索引包含所有需要查询的字段的值，我们就称之为覆盖索引；
- 不是所有索引都可以成为覆盖索引，覆盖索引必须存储索引列得值，而哈希索引、空间索引和全文索引等都不存储索引列得值，所以MySQL只能使用B-Tree索引做覆盖索引；
- 当发起一个被索引覆盖的查询时，在Explain的Extra列可以看到“Using index”的信息；

#### 使用索引扫描来做排序

- MySQL有两种方式可以生成有序的结果：通过排序操作，或按照索引顺序扫描；
- 如果Explain出来的type值为“index”，则说明MySQL使用了索引扫描来排序；
- 扫描索引本身是很快的，但是如果索引不能覆盖所需的全部列，那就不得不每扫描一条索引记录就回表查询一次对应的行，这基本上都是随机I/O，因此按索引顺序读取数据的速度通常要比顺序地全部扫描慢；

- 只有当索引的列排序和ORDER BY子句的顺序完全一致，并且所有列的排序方向都一样时，MySQL才能够使用索引来对结果做排序。ORDER BY子句同样需要满足最左前缀的要求（特殊情况：前导量为常量，如where column1 = 'XX' order by column2, column3，这里column1已在where子句被指定为常量）；


#### 压缩（前缀压缩）索引

MyISAM使用前缀压缩来减少索引的大小，从而让更多的索引可以放入内存中，这在某些情况下能极大地提高性能；

#### 冗余和重复索引

- MySQL允许在相同的列上创建多个索引，MySQL需要单独维护重复的索引，并且优化器在优化查询的时候也需要逐个地进行考虑，这会影响性能；
- 重复索引是指在相同地列上按照相同的顺序创建相同类型的索引，应该尽量避免这样创建重复索引；
- 冗余索引通常发生在为表添加新索引的时候，如有人可能会增加一个新的索引(A, B)，而不是扩展已有的索引(A)。大多数情况下都不需要冗余索引，应该尽量扩展已有的索引而不是创建新索引；

#### 索引和锁

- 索引可以让查询锁定更少的行，虽然InnoDB的行锁效率很高，内存使用也很少，但是锁定行的时候仍然会带来额外开销，其次，锁定超过需要的行会增加锁争用并较少并发性；
- InnoDB只有在访问行的时候才会对其加锁，而索引能够减少InnoDB访问的行数，从而减少锁的数量；

### 总结

在选择索引编写利用这些索引的查询时，有如下三个原则：

- 单行访问是很慢的。最好读取的块中能尽可能多所需要的行，使用索引可以创建位置引用以提升效率；
- 按顺序访问范围数据是很快的。原因：1.顺序I/O不需要多次磁盘寻道，所以比随机I/O快很多；2.如果服务器能够按需要顺序读取数据，那么就不再需要额外的排序操作，并且Group By查询也无须再做排序和按行按组进行聚合计算了；
- 索引覆盖查询是很快的。如果一个索引包含了查询需要的所有列，那么存储引擎就不需要再回表查找行；

## 查询性能优化

**Explain解析，Extra的含义**

| 语句                      | 含义                                                         |
| ------------------------- | ------------------------------------------------------------ |
| Using index               | 使用了覆盖索引                                               |
| Using where               | 在查找使用索引的情况下，需要回表去查询所需的数据             |
| Using index condition     | 查找使用了索引，但是需要回表查询数据                         |
| Using index & Using where | 查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询数据 |

### 慢查询基础：优化数据访问

- 确认应用程序是否在检索大量超过需要的数据；
- 确认MySQL服务器层是否在分析大量超过需要的数据行；

#### 是否向数据库请求了不需要的数据

典型案例：

- 查询不需要的记录，如查询100条，只取10条，应该用limit规避；
- 多表关联时返回全部列；
- 总是取出全部列（select *）。取出全部列会让优化器无法完成索引覆盖扫描的优化，还会为服务器带来额外的I/O、内存和CPU的消耗。但是select * 可以简化开发，提高代码复用性，还可以配合缓存机制使用；
- 重复查询相同的数据；

#### MySQL是否在扫描额外的记录

MySQL最简单的衡量查询开销的三个指标：

- 响应时间；
- 扫描的行数；
- 返回的行数；

一般MySQL能使用如下三种方式应用WHERE条件，由好到坏为：

- 在索引中使用WHERE条件过滤不匹配的记录，这是在存储引擎层完成的；
- 使用索引覆盖扫描返回记录，直接从索引中过滤不需要的记录并返回命中的结果，这是在MySQL服务器层完成的，但无须再回表查询记录；
- 从数据表中返回数据，然后过滤不满足的记录（Extra列出现Using Where），是在MySQL服务器层完成的，MySQL需要先从数据表读出记录再然后过滤；

### 重构查询的方式

#### 一个复杂的查询还是多个简单查询

- 传统实现认为网络通信、查询解析和优化是一件代价很高的事情，强调数据库层完成尽可能多的工作；
- 但是MySQL从设计上让连接和断开都很轻量级，在返回一个小的查询结果方面很高效；

#### 切分查询

有时候对于一个大查询我们需要分而治之，将大查询切分成小查询，每个查询功能完全一样，只完成一小部分，如：分多次删除数据；

#### 分解关联查询

把一个关联查询分解为多个查询。优势：

- 让缓存的效率更高。比如一个关联查询可以被分为三个查询，其中第一个查询的结果已经在另一个查询时被缓存了，则应用可以跳过第一个查询；
- 将查询分解后，执行单个查询可以减少锁的竞争；
- 在应用层做关联，可以更容易对数据库进行拆分，更容易做到高性能和可扩展；
- 查询本身效率也可能会有所提升；
- 可以减少冗余记录的查询；

### 查询执行的基础

当向MySQL发送了一个请求的时候，MySQL到底做了些什么：

1. 客户端发送一条查询给服务器；
2. 服务器先检查查询缓存，如果命中了缓存，则立即返回存储在缓存中的结果，否则进入下一阶段；
3. 服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划；
4. MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询；
5. 将结果返回给客户端；

#### MySQL客户端 / 服务器通信协议

MySQL客户端和服务器之间的通信协议是“半双工”的，这意味着在任何一个时刻，要么是由服务器向客户端发送数据，要么是由客户端向服务器发送数据，两者不能同时发生；

**查询状态**

| 状态                     | 说明                                                         |
| ------------------------ | ------------------------------------------------------------ |
| Sleep                    | 线程正在等待客户端发送新的请求；                             |
| Query                    | 线程正在执行查询或者正在将结果发送给客户端；                 |
| Locked                   | 在MySQL服务器层，线程正在等待表锁；在存储引擎级别实现的锁，例如InnoDB的行锁，并不会体现在线程状态中； |
| Analyzing and statistics | 正在收集存储引擎的统计信息，并生成查询的执行计划；           |
| Copying to tmp table     | 线程正在执行查询，并且将结果集都复制到一个临时表中；         |
| Sorting result           | 线程正在对结果集进行排序；                                   |
| Sending data             | 线程可能在多个状态之间传送数据，或者在生成结果集，或者在向客户端返回数据； |

#### 查询缓存

在解析一个查询语句之前，如果查询缓存是打开的，M有SQL会优先检查这个查询是否命中查询缓存中的数据。这个检查是通过一个对大小写敏感的哈希查找实现的。

#### 查询优化处理

查询优化处理包括解析SQL、预处理、优化SQL执行计划这几个子阶段。

**语法解析器和预处理**

MySQL通过关键字将SQL语句进行解析，并生成一颗对应的“解析树”。MySQL解析器将使用MySQL语法规则验证和解析查询，预处理则根据一些MySQL规则进一步检查解析树是否合法并验证权限；

**查询优化器**

- 现在语法树被认为是合法的了，需要由优化器将其转化为执行计划（优化器的作用就是在多种执行方式中找到最好的执行计划）；
- MySQL使用基于成本的优化器，即尝试预测一个查询使用某种执行计划时的成本，然后选择成本最小的一个（成本基于每个表或索引的页面个数、索引的基数（索引中不同值的数量）、索引和数据行的长度、索引分布）；
- 有很多原因会导致MySQL优化器选择错误的执行计划：1.统计信息不准确；2.执行计划中的成本估算不等同于实际执行的成本；3.MySQL的最优和你想的最优不一样（不止时间）；4.MySQL从不考虑其他并发执行的查询等；

一些MySQL能够处理的优化类型：

- 重新定义关联表的顺序；
- 外连接转化成内连接；
- 使用等价变换规则（如5=5 and a > 5将被改写a > 5）；
- 优化COUNT()、MIN()和MAX()；
- 预估并转化为常数表示式；
- 覆盖索引扫描；
- 子查询优化；
- 提前终止查询；
- 等值传播；
- 列表IN()的比较；（很多数据库系统中，IN()完全等同于多个OR条件的子句，但是在MySQL中，IN()列表中的数据会被先进行排序，然后用二分查找的方式来确定列表中的值是否满足条件）；

**数据和索引的统计信息**

MySQL的统计信息由存储引擎实现

**MySQL如何执行关联查询**

MySQL对任何关联都执行嵌套循环关联操作，即MySQL先在一个表中循环取出单条数据，然后再嵌套循环到下一个表中寻找匹配的行，依次直到找到所有表中匹配的行为止。然后根据各个表匹配的行返回查询中需要的各个列。

**执行计划**

和很多其他关系数据库不同，MySQL不会生成查询字节码来执行查询，MySQL生成查询的一颗指令树，然后通过存储引擎完成这颗指令树并返回结果，最终的执行计划包含了重构查询的全部信息。（MySQL的执行计划总是一颗左侧深度优先的树）

**关联查询优化器**

- MySQL优化器最重要的一部分就是关联查询优化，它决定了多个表关联时的顺序，关联查询优化器通过评估不同顺序时的成本来选择一个代价最小的关联顺序；
- 如果有超过n个表的关联，那么需要检查n!种关联顺序，我们称之为所有可能的执行计划的搜索空间，当搜索空间非常大的时候，优化器不可能逐一评估每一种关联顺序的成本，这时优化器使用“贪婪”搜索的方式查找“最优”的关联顺序。

**排序优化**

- 无论如何排序都是一个成本很高的操作，所以从性能角度考虑，应尽可能避免排序或者尽可能避免对大量数据进行排序；
- 当不能使用索引生成排序结果的时候，MySQL需要自己进行排序，如果数据量小则在内存中进行，如果数据量大则需要使用磁盘，MySQL将这个过程统一称为文件排序（filesort)；
- 如果需要排序的数据量小于“排序缓冲区”，MySQL使用内存进行“快速排序”操作，如果内存不够排序，则么MySQL会将数据分块，对每个独立的块使用“快速排序”，并将各个块的排序结果放在磁盘上，然后将各个排序的块进行合并，最后返回排序结果。

#### 查询执行引擎

在解析和优化阶段，MySQL将生成查询对应的执行计划，MySQL的查询执行引擎则根据这个执行计划来完成整个查询。

#### 返回结果给客户端

- 即使查询不需要返回结果集给客户端，MySQL仍然会返回这个查询的一些信息，如该查询影响到的行数；
- 如果查询可以被缓存，那么MySQL在这个阶段也会将结果存放到查询缓存中；
- MySQL将结果集返回客户端是一个增量、逐步返回的过程，一旦服务器处理完最后一个关联表，开始生成第一条结果时，MySQL就可以开始向客户端逐步返回结果集了；

### MySQL查询优化器的局限性

#### 关联子查询

- MySQL的子查询实现得非常糟糕，最糟糕得一类查询是WHERE条件中包含IN()的子查询语句；
- 通常建议使用EXISTS()等效的改写查询来获取更好的效率；
- 并不是所有关联子查询的性能都会很差，需进行测试；

#### UNION的限制

如果希望UNION的各个子句能够根据LIMIT只取部分结果集，或者希望能够先拍好序再合并结果集的话，就需要在UNION的各个子句中分别使用这些子句；

#### 索引合并优化

当WHERE子句中包含多个复杂条件的时候，MySQL能够访问单个表的多个索引以合并和交叉过滤的方式来定位需要查找的行；

#### 并行执行

MySQL无法利用多核特性来并行执行查询；

#### 哈希关联

MySQL并不支持哈希关联，所有关联都是嵌套循环关联，不过可以建立一个哈希索引来曲线地实现哈希关联；

#### 松散索引扫描

MySQL不支持松散索引扫描，无法按照不连续的方式扫描一个索引；

#### 最大值和最小值优化

对于MIN()和MAX()查询，MySQL的优化做得并不好。例如：

`select min(actor_id) from actor where first_name = 'PENELOPE';`

这里first_name字段上没有索引，MySQL会进行一次全表索引。但是如果MySQL能够进行主键扫描，理论上当MySQL读到第一个满足条件的记录的时候就是我们需要找的最小值了。

#### 在同一个表上查询和更新

MySQL不允许对同一张表同时进行查询和更新；

### 查询优化器的提示（hint）

如果对优化器选择的执行计划不满意，可以使用优化器提供的几个提示（hint）来控制最终的执行计划。

- HIGH_PRIORITY和LOW_PRIORITY：多个语句同时访问某一个表的时候，语句的优先级高低；
- DELAYED：MySQL会将使用该提示的语句立即返回给客户端，并将插入的行数据放入到缓冲区，然后在表空闲时批量将数据写入；
- STRAIGHT_JOIN：联表查询时控制表之间的关联顺序；
- SQL_SMALL_RESULT和SQL_BIG_RESULT：前者告诉优化器结果集会很小，可以将结果集放在内存中的索引临时表，后者告诉结果集会很大，建议使用磁盘临时表做排序；
- SQL_BUFFER_RESULT：告诉优化器将查询结果放入到一个临时表，然后尽可能快地释放表锁；
- SQL_CACHE和SQL_NO_CACHE：告诉MySQL这个结果集是否应该缓存在查询缓存中；
- SQL_CALC_FOUND_ROWS：查询中加上该提示，MySQL会计算除去LIMIT子句后这个查询要返回的结果集地总数，而实际上只返回LIMIT要求的结果集；
- FOR UPDATE和LOCK IN SHARE MODE：对符合查询条件的数据行加锁（仅对实现了行级锁的存储引擎有效）；
- USE INDEX、IGNORE INDEX和FORCE INDEX：告诉优化器使用或者不使用哪些索引来查询记录；
- optimizer_search_depth：控制优化器在穷举执行计划的限制；
- optimizer_prune_level：默认打开，让优化器根据需要扫描的行数来决定是否跳过某些执行计划；
- optimizer_switch：包含了一些开启/关闭优化器特性的标志位；

### 优化特定类型的查询

#### 优化count()查询

**COUNT()的作用**

- 统计某个列值的数量（要求列值是非空的），也可以统计行数；
- 使用count(*)时，\* 并不会扩展为所有的列，而是统计所有的行数，而count(column)则是统计列不为null的行数；

#### 优化关联查询

- 确保ON或者USING子句的列上有索引。一般来说，除非有其他理由，否则只需要在关联顺序中的第二个表的相应列上创建索引；
- 确保任何的Group BY和ORDER BY中的表达式只涉及一个表中的列，这样MySQL才有可能使用索引来优化这个过程；
- 当升级MySQL的时候需要注意：关联语法、运算符优先级等其他可能会发生变化的地方；

#### 优化子查询

尽可能使用关联查询代替；

#### 优化GROUP BY和DISTINCT

- MySQL使用同样的方法优化这两种查询，MySQL优化器会在内部处理的时候相互转化这两类查询；
- 它们都可以使用索引来优化，这也是最有效的优化办法；

#### 优化LIMIT分页

- 常见问题：偏移量非常大；

- 将LIMIT查询转换为已知位置的查询，让MySQL通过范围扫描获得到对应的结果；

- 还可以记录上次取数据的位置，下次扫描可以直接从该书签记录的位置开始扫描，这样就可以避免使用OFFSET；

- 尽可能使用索引覆盖扫描，如：

  ```sql
  select * from user order by id limit 20000, 20;
  select u.* from user u inner join (select id from user order by id limit 20000, 20) ids using(id);
  ```

#### 优化UNION查询

- MySQL总是通过创建并填充临时表的方式来执行UNION查询，因此很多优化策略在UNION查询中都没法很好地使用；
- 除非确实需要服务器消除重复的行，否则就一定要UNION ALL；

## MySQL高级特性

### 分区表

- 对用户来说，分区表是一个独立的逻辑表，但是底层由多个物理子表组成。实现分区的代码实际上是对一组底层表的句柄对象（Handler Object）的封装，对分区表的请求，都会通过句柄对象转化成存储引擎的接口调用；
- MySQL在创建表时使用Partition By子句定义每个分区存放的数据，在执行查询的时候，优化器会根据分区定义过滤那些没有我们需要数据的分区；

分区适用于以下场景：

- 表非常大以至于无法全部都放在内存中，或者只在表的最后部分有热点数据，其他均是历史数据；
- 分区表的数据更容易维护；
- 分区表的数据可以分布在不同的物理设备上，从而高效地利用多个硬件设备；
- 可以使用分区表来避免某些特殊的瓶颈；
- 如果需要，还可以备份和恢复独立的分区，这在非常大的数据集的场景下效果非常好；

分区表的限制：

- 一个表最多只能有1024个分区；
- 在MySQL5.1中，分区表示式必须是整数，或者是返回整数的表达式；
- 如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来；
- 分区表中无法使用外键约束；
- 所有分区都必须使用相同的存储引擎；

#### 查询优化

- 在访问分区表时，在Where条件中带入分区列，可以让优化器过滤掉无须访问的分区；
- 即便在创建分区时可以使用表示式，但在查询时却只能根据列来过滤分区；

### 视图

两种实现方式：

- **合并算法**：合并查询视图的SQL和视图的SQL，然后向数据库服务器查询；
- **临时表算法**：服务器先执行在底层表上定义的视图SQL，将数据保存在和视图结构一样的临时表中，然后服务器执行SQL，从临时表查询结果；

### 外键约束

- InnoDB是MySQK唯一支持外键的内置存储引擎；
- 使用外键是有成本的，外键通常要求每次在修改数据时都要在另外一张表中多次执行一次查找操作；
- 如果想确保两个相关表始终有一致的数据，那么使用外键比在应用程序中检查一致性的性能要高得多；
- 外键约束使得查询需要额外访问一些别的表，这也意味着需要额外的锁；

### 在MySQL内部存储代码

MySQL允许通过触发器、存储过程、函数、事件的形式来存储代码；

优点：

- 在服务器内部执行，离数据最近，可节省带宽和网络延迟；
- 这是一种代码重用，可以方便地统一业务规则，保证某些行为总是一致，所以也可以为应用提供一定地安全性；
- 它可以简化代码的维护和版本更新；
- 可通过提供更细粒度的权限控制来帮助提升安全，应用程序可以通过存储过程的接口访问那些没有权限的表。一个常见的例子是银行用户转移资金的存储过程：这个存储过程可以在一个事务中完成资金转移和记录用于审计的日志；
- 服务器端可以缓存存储过程的执行计划，这对于需要反复调用的过程，会大大降低消耗；
- 因为是在服务端部署的，所以部署、维护都可以在服务器端完成，所以存储程序的维护工作会很简单；
- 可以在应用开发和数据库开发人员之间更好地分工；

缺点：

- MySQL本身没有提供好用的开发和调试工具；
- 较之应用程序的代码，存储代码效率要稍微差些；
- 存储代码可能会给应用程序代码的部署带来额外的复杂性；
- 存储程序都部署在服务器内，所以可能有安全隐患，如果将非标准的加密功能放在存储程序中，那么若数据库被攻破，数据也就泄漏了；
- 存储过程会给数据库服务器增加额外的压力，而数据库服务器的扩展性相比应用服务器要差很多；
- MySQL并没有什么选项可以控制存储程序的资源消耗，所以存储过程中的一个小错误，可能直接把服务器拖死；
- 存储代码在MySQL中的实现也有很多限制——执行计划缓存是连接级别的，游标的物化和临时表相同；

### 绑定变量（prepared statement）

- 当创建一个绑定变量SQL时，客户端向服务器发送了一个SQL语句的原型，服务器端收到这个SQL语句句柄后，解析并存储这个SQL语句的部分执行计划，返回给客户端一个SQL语句处理句柄；
- 可以通过向服务器端发送各个问号的取值和这个SQL的句柄来执行一个具体的查询，返回使用这样的方式执行具体的查询；

MySQL在使用绑定变量的时候可以更高效地执行大量的重复语句：

- 服务器端只需要解析一次SQL语句；
- 服务器端某些优化器的工作只需要执行一次，因为它会缓存一部分的执行计划；
- 以二进制的方式只发送参数和句柄，比起每次都发送ASCII码文本效率更高；
- 不需要发送整个查询语句到服务器端，所以网络开销会更小；
- MySQL在存储参数时，直接将其存放到缓存中，不再需要在内存中多次复制；

绑定变量相对也更安全，无须再应用程序中处理转义，大大减少了SQL注入和攻击的风险；

#### 绑定变量的限制

- 绑定变量是会话级别的，所以连接之间不能共用绑定变量句柄。同样的，一旦连接断开，原来的句柄也不能再使用了（连接池和持久化连接可以在一定程度上缓解这个问题）；
- 并不是所有的时候使用绑定变量都能获得更好的性能（比如只执行一次SQL）；
- 如果总是忘记释放绑定变量资源，则在服务器端很容易发生资源泄漏。绑定变量SQL总数的限制是一个全局限制，所以某一个地方的错误可能会对所有其他的线程都产生影响；

### 字符集和校对

字符集是指一种从二进制编码到某类字符符号的映射，校对是指一组用于某个字符集的排序规则；

### 全文索引

通过数值比较、范围过滤等就可以完成绝大多数我们需要的查询了，但是如果你希望通过关键字的匹配来进行查询过滤，那么就需要基于相似度的查询，而不是原来的精确数值比较。全问索引就是为这种场景设计的；

### 分布式（XA）事务

MySQL中有两种XA事务，一方面MySQL可以参与到外部的分布式事务中，另一方面，还可以通过XA事务来协调存储引擎和二进制日志。

**XA事务**

- XA（eXtended Architecture）是指有X/Open组织提出的分布式交易处理规范，XA是一个分布式事务协议。XA协议主要定义了事务管理器TM（Transaction Manager，协调者）和资源管理器RM（Resource Manager，参与者）之间的接口。其中，资源管理器往往由数据库实现，如Oracle、MySQL，这些商业数据库都实现了XA接口，而事务管理器作为全局的调度者，负责各个本地资源的提交和回滚。
- XA事务是基于两阶段提交（Two-phaseCommit，2PC）协议实现的，阶段一为准备阶段，即所有参与者准备执行事务并锁住需要的资源，当参与者Ready时，向TM汇报自己已经准备好。阶段二为提交阶段，当TM确认所有参与者都Ready后，向所有参与者发送COMMIT命令；
- XA事务的缺点是性能不好，且无法满足高并发场景，一个数据库的事务和多个数据库间的XA事务性能会相差很多，因此要避免XA事务，如可以将数据写入本地，用高性能的消息系统分发数据，或使用数据库复制技术。只有在其他办法都无法实现业务需求，且性能不是瓶颈时才使用XA；

#### 内部XA事务

- MySQL本身的插件式架构导致在其内部需要使用XA事务，其各个存储引擎是完全独立的，彼此不知道对方的存在，所以一个跨存储引擎的事务就需要一个外部的协调者；
- 如果把MySQL记录的二进制日志操作看作一个独立的“存储引擎”，就不难理解为什么即使是一个存储引擎参与的事务仍然需要XA事务了，在存储引擎提交的同时，需要将提交的信息写入二进制日志，这就是一个分布式事务；

#### 外部XA事务

- MySQL能够作为参与者完成一个外部的分布式事务；
- 因为通信延迟和参与者本身可能失败，所以外部XA事务比内部消耗会更大，如果在广域网中使用XA事务，通常会因为不可预测的网络性能导致事务失败；
- 通常还可以使用别的方式实现高性能的分布式事务，例如可以在本地写入数据，并将其放入队列，然后在一个更小、更快的事务中自动分发。还可以使用MySQL本身的复制机制来发送数据；

### 查询缓存

- MySQL查询缓存保存查询返回的完整结果，当查询命中该缓存，MySQL会立即返回结果，跳过了解析、优化和执行阶段；
- 查询缓存系统会跟踪查询中涉及的每个表，如果这些表发生变化，那么和这个表相关的所有的缓存数据都将失效；

#### MySQL如何判断缓存命中

- 缓存放在一个引用表中，通过一个哈希值引用，这个哈希值包括了查询本身、当前要查询的数据库、客户端协议的版本等因素 ；
- 任何字符上的不同，例如空格、注释都会导致缓存的不命中；

MySQL的查询缓存在很多时候可以提升查询性能，但是打开查询缓存对读和写操作都会带来额外的消耗：

- 该查询在开始之前必须先检查是否命中缓存；
- 如果这个读查询可以被缓存，那么完成执行后，MySQL若发现查询缓存中没有这个查询，会将其结果存入查询缓存，这会带来额外的系统消耗；
- 这对写操作也会有影响，因为当向某个表写入数据时，MySQL必须将对应表的所有缓存都设置失效；

#### 如何配置和维护查询缓存

- query_cache_type：是否打开缓存；
- query_cache_size：查询缓存使用的总内存空间，单位是字节；
- query_cache_min_res_unit：查询缓存中分配内存块时的最小单位；
- query_cache_limit：MySQL能够缓存的最大查询结果；
- query_cache_wlock_invalidate：如果某个数据表被其他的连接锁住，是否仍然从查询缓存中返回结果；

## 优化服务器设置

### MySQL配置的工作原理

MySQL从命令行参数和配置文件中获取配置信息；

#### 语法、作用域和动态性

- 配置项可以是服务器级的（全局作用域），也可以是会话作用域的，还可以是对象级的；
- 除了在配置文件中设置变量，有很多变量也可以在服务器运行时修改，MySQL将这些归为动态配置变量；

### 配置内存使用

按照以下步骤来配置内存：

1. 确定可以使用的内存上限；
2. 确定每个连接MySQL需要使用多少内存，例如排序缓冲和临时表；
3. 确定操作系统需要多少内存才够用，包括同一台机器上其他程序使用的内存，如定时任务；
4. 把剩下的内存全部给MySQL的缓存，例如InnoDB的缓冲池；

#### InnoDB缓冲池

InnoDB缓冲池不仅缓存索引，还会缓存行的数据、自适应哈希索引、插入缓冲、锁，以及其他内存数据结构。InnoDB还使用缓冲池来帮助延迟写入，这样就能合并多个写入操作，然后一起顺序地写回；

#### MyISAM键缓存

MyISAM只有一个键缓存，但是也可以创建多个，不像InnoDB和其他一些存储引擎，MyISAM自身只缓存索引，不缓存数据。如果大部分是MyISAM表，就应该为键缓存分配比较多的内存；

#### 线程缓存

保存那些没有与连接关联但是准备为后面新的连接服务的线程，当一个新的连接创建时，如果缓存中有线程存在，则从缓冲中删除一个线程，并且把它分配给这个新的连接；

### 配置MySQL的I/O行为

#### InnoDB I/O配置

**InnoDB事务日志**

- InnoDB使用日志来减少提交事务时的开销。因为日志中已经记录了事务，就无须在每个事务提交时把缓冲池的脏块刷新到磁盘中。事务修改的数据和索引通常会映射到表空间的随机位置，所以刷新这些变更到磁盘需要很多随机I/O；
- InnoDB用日志把随机I/O变成顺序I/O，一旦日志安全写到磁盘，事务就持久化了。如果断电了，InnoDB可以重放日志并且恢复已经提交的事务；
- InnoDB最终还是需要把变更写道数据文件，因为日志有固定的大小，InnoDB的日志是环形方式写的：当写到日志的尾部，会重新跳转到开头继续写，但不会覆盖还没应用到数据文件的日志记录；
- InnoDB使用一个后台线程智能地刷新这些变更到数据文件，这个线程可以批量组合写入，使得数据写入更顺序，以提交效率；
- InnoDB使用多个文件作为一组循环日志，整体日志文件大小受控于innodb_log_file_size（每个文件大小）和innodb_log_files_in_group（每组有多少个文件）两个参数，通常只需要修改前者；
- 当InnoDB变更任何数据时，会写一条变更记录到内存日志缓冲区。在缓冲满的时候、事务提交的时候、或者每一秒钟，InnoDB会刷写缓冲区的内容到磁盘日志文件。变量innodb_log_buffer_size可以控制日志缓冲区的大小；

**InnoDB表空间**

InnoDB把数据保存在表空间内，本质上是一个由一个或多个磁盘文件组成的虚拟文件系统。InnoDB用表空间实现很多功能，并不只是存储表和索引，它还保存了回滚日志、插入缓冲、双写缓冲以及其他内部数据结构；

### 配置MySQL并发

#### InnoDB并发配置

innodb_thread_concurrency变量限制一次性可以有多少线程进入内核；

## 操作系统和硬件优化

### 什么限制了MySQL的性能

最常见的两个瓶颈是CPU和I/O资源；

### 平衡内存和磁盘资源

配置大量内存最大的原因其实不是因为可以在内存中保存大量数据，最终目的是避免磁盘I/O，因为磁盘I/O比在内存中访问数据要慢得多；

#### 随机I/O和顺序I/O

- 数据库服务器同时使用顺序和随机I/O，随机I/O从缓存中获益最多（因为缓存随机分布的数据将有助于避免昂贵的磁盘寻道）；
- 顺序I/O比随机I/O快；
- 存储引擎执行顺序读比随机读快；

## 复制

MySQL内建的复制功能是构建基于MySQL的大规模，高性能应用的基础

### 复制概述

- 复制解决的基本问题是让一台服务器的数据与其他服务器保持同步；
- MySQL支持两种复制方式：基于行的支付和基于语句的复制。两种方式都是通过在主库上记录二进制日志、在备库重放日志的方式来实现异步的数据复制，这意味着在同一时间点备库上的数据可能与主库存在不一致，并且无法保证主备之间的延迟；

#### 复制解决的问题

**数据分布**：MySQL复制通常不会对带宽造成很大的压力（基于行的支付会比基于语句的复制模式的带宽压力更大）。你可以随意地停止或开始复制，并在不同的地理位置来分布数据备份，例如不同的数据中心。即使在不稳定的网络环境下，远程复制也可以工作，但如果为了保持很低的复制延迟，最好有一个稳定的、低延迟连接；

**负载均衡**：通过MySQL复制可以将读操作部分到多个服务器上，实现对读密集型应用的优化，并且实现很方便，通过简单的代码修改就能实现基本的负载均衡；

**备份**：对于备份来说，复制是一项很有意义的技术补充；

**高可用性和故障切换**：复制能够帮助应用程序避免MySQL单点失败，一个包含复制的设计良好的故障切换系统能够显著地缩短宕机时间；

**MySQL升级测试**：使用一个更高版本的MySQL作为备库，保证在升级全部实例前，查询能够在备库按照预期执行；

#### 复制如何工作

1. 在主库上把数据更改记录到二进制日志（Binary Log）中，在每次准备提交事务完成数据更新前，主库将数据更新的事件记录到二进制日志中，MySQL会按事务提交的顺序而非每条语句的执行顺序来记录二进制日志。在记录二进制日志后，主库会告诉存储引擎可以提交事务了；
2. 备库将主库上的二进制日志复制到自己的中继日志（Relay Log）中。首先备库会启动一个工作线程（I/O线程），I/O线程跟主库建立一个普通的客户端连接，然后在主库上启动一个特殊的二进制转储（binlog dump）线程，这个二进制转储线程会读取主库上二进制日志中的事件，备库I/O线程会将接收到的事件记录到中继日志中；
3. 备库的SQL线程读取中继日志中的事件，将其重放到备库数据之上；

这种复制架构实现了获取事件和重放事件的解耦，允许这两个过程异步进行，也就是说I/O线程能够独立于SQL线程之外工作。但是这种架构也限制了复制的过程，其中最重要的一点是在主库上并发运行的查询在备库只能串行化执行，这是很多工作负载的性能瓶颈所在；

### 配置复制

#### 创建复制账号

在主库创建一个用户并赋予其合适的权限，在备库运行的I/O线程会建立一个到主库的TCP/IP连接，备库I/O线程以该用户名连接到主库并读取其二进制日志；

#### 配置主库和备库

- 修改主库my.cnf文件以配置log_bin和server_id；
- 备库同样需要配置log_bin、server_id等；

#### 启动复制

下一步是告诉备库如何连接到主库并重放其二进制日志，使用CHANGE MASTER TO语句；

#### 从另一个服务器开始复制

有一个已经运行了一段时间的主库，然后用一台新安装的备库与之同步，此时这台备库还没有数据；

需要有三个条件来让主库和备库保持同步：

- 在某个时间点的主库的数据快照；
- 主库当前的二进制日志文件，和获得数据快照时在该二进制日志文件中的偏移量；
- 从快照时间到现在的二进制日志；

以下是一些从别的服务器克隆备库的方法：

- **使用冷备份**：关闭主库，把数据复制到备库，重启后在备库通过执行CHANGE MSTER TO指向主库新的二进制日志文件的起始处；
- **使用热备份**：如果仅使用了MyISAM表，可以在主库运行时使用mysqlhotcopy或rsync来复制数据；
- **使用mysqldump**：如果只包含InnoDB表，可以使用mysqldump命令转储主库数据并将其加载到备库，然后设置相应的二进制日志坐标；
- **使用快照或备份**：只要知道对应二进制日志坐标，就可以使用主库的快照或者备份来初始化备库。只需要把备份或快照恢复到备库，然后使用CHANGE MASTER TO指定二进制日志的坐标；

#### 推荐的复制配置

主库上最重要的选项是sync_binlog，如果开启该选项，MySQL每次在提交事务前会将二进制日志同步到磁盘上，保证在服务器崩溃时不会丢失事件；

### 复制的原理

#### 基于语句的复制

- 基于语句的复制模式下，主库会记录那些造成数据更改的查询，当备库读取并重放这些事件时，实际上只是把主库上执行过的SQL再执行一遍；
- 好处是实现简单，且二进制日志里的事件更加紧凑；
- 缺点是主库上的数据更新除了执行的语句外，还可能依赖于其他因素，例如，同一个SQL在主库和备库上执行的事件可能稍微或很不相同，还存在着一些无法被正确复制的SQL。另一个问题是更新必须是串行的，这需要更多的锁；

#### 基于行的复制

- 这种方式会将实际数据记录在二进制日志中，其最大的好处是可以正确地复制每一行；
- 由于无须重放更新主库数据的查询，某些情况下使用基于行的复制模式能够更高效地复制数据；
- MySQL能够在两种复制模式间动态切换，默认情况下使用的是基于语句的复制方式，如果发现语句无法被正确地复制，就切换到基于行的复制模式；

#### 复制文件

除了前面介绍的二进制日志文件和中继日志文件，还有其他文件会被用到：

- **mysql-bin.index**：当在服务器上开启二进制日志时，同时会生成一个和二进制日志同名的但是以.index作为后缀的文件，该文件用于记录磁盘上的二进制日志文件，“index”表示这个文件的每一行包含了二进制文件的文件名；
- **mysql-relay-bin-index**：中继日志的索引文件，和mysql-bin.index的作用类似；
- **master.info**：用于保存备库连接到主库所需要的信息，格式为纯文本，不同的MySQL版本，其记录的信息也可能不同，此文件不能删除，否则备库在重启后无法连接到主库；
- **relay-log.info**：包含了当前备库复制的二进制日志和中继日志坐标；

#### 发送复制事件到其他备库

log_slave_updates选项可以让备库变成其他服务器的主库。在设置了该选项后，MySQL会将其执行过的事件记录到它自己的二进制日志中。这样它的备库就可以从其日志中检索并执行事件。

### 复制拓扑

可以在任意个主库和备库之间建立复制，只有一个限制：每个备库只能有一个主库。记住以下基本原则：

- 一个MySQL备库实例只能有一个主库；
- 每个备库必须有一个唯一的服务器ID；
- 一个主库可以有多个备库；
- 如果打开了log_slave_updates选项，一个备库可以把其主库上的数据变化传播到其他备库；

#### 一主库多备库

适用场景：

- 为不同的角色适用不同的备库（例如添加不同的索引或适用不同的存储引擎）；
- 把一台备库当作待用的主库，除了复制没有其他数据传输；
- 将一台备库放到远程数据中心，用作灾难恢复；
- 延迟一个或多个备库，以备灾难恢复；
- 使用其中一个备库，作为备份、培训、开发或测试使用服务器；

#### 主主复制

- 主主复制（也叫双主复制或双向复制）包含了两台服务器，每一个都被配置成对方的主库和备库；
- 这种配置最大的问题是如何解决冲突，两个可写的互主服务器导致的问题非常多，这通常发生在两台服务器同时修改一行记录，或同时在两台服务器上向一个包含AUTO_INCREMENT列的表里插入数据；
- 此模式有一些特殊的应用场景，如两个处于不同地理位置的办公室，都需要一份可写的数据拷贝；

#### 主动-被动模式下的主主复制

- 其中一台服务器是只读的被动服务器；
- 这种方式使得反复切换主动和被动服务器非常方便，因为服务器的配置是对称的，这使得故障转移和故障恢复很容易。它也可以让你在不关闭服务器的情况下执行维护、优化表、升级操作系统或其他任务；

#### 拥有备库的主主结构

即在主主结构的基础上为每个主库增加一个备库；

#### 环形复制

- 环形结构可以有三个或更多的主库，每个服务器都是在它之前的服务器的备库，是在它之后的服务器的主库；
- 如果从环中移除一个节点，这个节点发起的事件就会陷入无限循环，因此应该尽量避免环形结构；

#### 主库、分发主库以及备库

- 当备库足够多时，会对主库造成很大的负载，每个备库会在主库上创建一个线程，并执行binlog dump命令，该命令会读取二进制日志文件中的数据并将其发送给备库；
- 如果需要多个备库，一个好办法是从主库移除负载并使用分发主库，分发主库事实上也是一个备库，它的唯一目的就是提取和提供主库的二进制日志，多个备库连接到分发主库，使主库摆脱负担；
- 使用分发主库的一个主要的缺点是无法使用一个备库来代替主库，因为由于分发主库的存在，导致各个备库与原始主库的二进制日志坐标已经不相同；

#### 树或金字塔型

- 如果正在将主库复制到大量的备库中，不管是把数据分发到不同的地方，还是提供更高的读性能，使用金字塔结构都能够更好地管理；
- 好处是减轻了主库的负担，缺点是中间层出现的任何错误都会影响到多个服务器；

## 可扩展的MySQL

### 什么是可扩展性

- 可扩展性表明了当需要增加资源以执行更多工作时系统能够获得划算的等同提升的能力，缺乏扩展能力的系统在达到收益递减转折点后密集，将无法进一步增长；
- 容量表示在一定时间内能够完成的工作量，但容量必须是可以有效利用的；

### 扩展MySQL

#### 向上扩展（垂直扩展）

购买更多性能强悍的硬件

#### 向外扩展（水平扩展）

可以把向外扩展策略分为三个部分：复制、拆分以及数据分片（sharding）；

**按功能拆分**：按职责拆分，不同的节点执行不同的任务；

**数据分片**：

- 在目前用于扩展大型MySQL应用的方案中，数据分片是最通用且最成功的方法。它把数据分割成一小片，存储到不同的节点中；
- 数据分片的最大挑战是查找和获取数据；
- 选择分区键时，尽可能选择那些能够避免跨分片查询的，但同时也要让分片足够小；
- 复杂的数据模型会使数据分片更加困难，许多应用拥有多个分区键；

将数据分配分片中有两种主要的方法：固定分配和动态分配，两种方法都需要一个分区函数。固定分配使用的分区函数仅仅依赖于分区键的值，如哈希函数和取模运算。固定分配的缺点是：

- 如果分片很大并且数量不多，则难以平衡不同分片间的负载；
- 无法自定义数据放到哪个分片上；
- 修改分片策略通常比较困难，因为需要重新分配已有的数据；

另一个选择是使用动态分配，如可以使用一个包含用户id和分片id的分片表。动态分配增加了分区函数的开销，因为需要额外调用一次外部资源。动态分配的最大好处是可以对数据存储位置做细粒度的控制，这使得均衡分配数据到分片更加容易；

**生成全局唯一ID**：当使用分片数据存储时，经常会需要在多台机器上生成全局唯一ID，可使用以下几种方法解决：

- 使用auto_increment_increment和auto_increment_offset，让MySQL以期望的增加值和偏移量来增加auto_increment列的值；
- 全局节点中创建表：在一个全局数据库节点中创建一个包含AUTO_INCREMENT列，要注意单点争用称为应用的性能瓶颈；
- 使用memcached的incr()函数或redis，需注意持久化的问题；
- 批量分配数字：从一个全局节点中请求一批数字，用完后再申请；
- 使用复合值：如使用分片号与自增数的组合；
- 使用GUID：不适合做InnoDB表的主键；

**分片工具**：设计数据分片应用时，首先要做的事情是编写能够查询多个数据源的代码，即抽象层，这个抽象层需要完成以下任务：

- 连接到正确的分片并执行查询；
- 分布式一致性校验；
- 跨分片结果集聚合；
- 跨分片关联操作；
- 锁和事务管理；
- 创建新的数据分片并重新平衡分片；

### 负载均衡

在一个服务器集群中尽可能地平均负载量，通常的做法是在服务器前端设置一个负载均衡器，然后负载均衡器请求的连接路由到最空闲的可用服务器。负载均衡有五个常见目的：

**可扩展性**：负载均衡对某些扩展策略有所帮助，例如读写分离时从备库读数据；

**高效性**：有助于更有效地使用资源，因为它能够控制请求被路由到何处。如果服务器处理能力各不相同，这就尤为重要：你可以把更多地工作分配给性能更好的机器；

**可用性**：一个灵活的负载均衡解决方案能够使用时刻保持可用的服务器；

**透明性**：客户端无须知道是否存在负载均衡设置，也不需要关心在负载均衡器的背后有多少机器；

**一致性**：如果应用是有状态的，那么负载均衡器就应将相关的查询指向同一个服务器，以防状态丢失；

## 高可用性

### 导致宕机的原因

需要注意的地方：

- 磁盘空间耗尽；
- 运行很糟糕的SQL，或服务器Bug或错误的行为；
- 糟糕的Schema和索引设计是第二大影响性能的问题；
- 复制问题通常由于主备数据不一致导致；
- 数据丢失问题通常由于DROP TABLE的误操作导致；

### 如何实现高可用性

- 尝试避免导致宕机的原因来减少宕机时间；
- 尽量保证在发生宕机时能够快速恢复；

这两个维度可以通过两个相关的度量来确定：平均失效时间（MTBF）和平均恢复时间（MTTR）；

### 避免单点失效

#### 共享存储或磁盘复制

- 共享存储能够为数据库服务器和存储解耦合，使用共享存储时，服务器能够正常挂载文件系统并进行操作，如果服务器挂了，备用服务器可以挂载相同的文件系统，执行需要的恢复操作；
- 共享存储可以避免除存储外的其他任何组件失效所引起的数据丢失，并为非存储组件建立冗余提供可能；
- 共享存储本身仍是可能失效的单点；

#### MySQL同步复制

当使用同步复制时，主库上的事务只有在至少有一个备库上提交后才能认为其执行完成。这实现了两个目标：当服务器崩溃时没有提交的事务会丢失，并且至少有一个备库拥有实时的数据副本；

### 故障转移和故障恢复

- 冗余是很好的技术，但是实际上只有在遇到故障需要恢复时才会用到；
- 故障转移最重要的部分就是故障恢复；

## 备份与恢复

### 为什么要备份

- 灾难恢复；
- 回滚已删除数据；
- 审计；
- 测试；

### 设计MySQL备份方案

对备份的建议：

- 在生产实践中，对大数据库来说，物理备份是必须；
- 保留多个备份集；
- 定期从逻辑备份或物理备份中抽取数据进行恢复测试；
- 保存二进制日志以用于基于故障时间点的恢复；
- 完全不借助备份工具本身来监控备份和备份的过程；
- 通过演练整个恢复过程来测试备份和恢复；
- 考虑对服务器的访问的安全性；

#### 在线备份还是离线备份

- 如果可能，关闭MySQL做备份是最简单最安全的；
- 由于一致性的需求，对服务器进行在线备份会有明显的服务中断；
- 众多备份方法的一个最大问题是它们会使用FLUSH TABLES WITH READ LOCK操作，这会导致MySQL关闭并锁住所有的表（对于MyISAM引擎）；

在规划备份时，需考虑：

- 锁时间：持有锁的时间；
- 备份时间：复制备份到目的地需要多久；
- 备份负载：备份时对服务器的影响：
- 恢复时间：把备份镜像从存储位置复制到MySQL服务器，重放二进制日志等，需要多久；

#### 逻辑备份还是物理备份

- 逻辑备份：将数据包含在一种MySQL能够解析的格式中；
- 物理备份：直接复制原始数据文件；

物理备份通常更加简单高效，但是对于需要长期保留的备份，或者满足法律合规要求的备份，尽量不要完全依赖物理备份，至少每隔一段时间还是需要做一次逻辑备份；

#### 存储引擎和一致性

**数据一致性**

- 在备份时，应该考虑是否需要数据在指定时间点一致；
- 如果使用的不是事务型存储引擎，则只能在备份时用LOCK TABLES来锁住所有要一起备份的表，备份完再释放锁；
- InnoDB的多版本控制功能可以帮到我们：开始一个事务，转储一组相关的表，然后提交事务；

**文件一致性**

- 对于非事务性存储引擎，可能的选项是锁住并刷新表；
- 对于InnoDB，确保文件在磁盘上一致更困难，因为有后台运行的插入缓存、日志和写线程；